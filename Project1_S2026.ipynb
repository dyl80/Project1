{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Understanding and Training Regression Models\n",
    "## Regardless of the level you are in this course, you are NOT allowed to use import tools from the scipy or sci-kit learn.  The only imports allowed on this project are pandas, numpy, and matplotlib.\n",
    "\n",
    "### Name:\n",
    "### Course Level:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "* In this project, we explore the application of regression in analyzing and modeling relationships between input variables. The project will be broken into sections in which students registered for CSC 448  and CSC 548 will complete Problems A - C, and CSC 548 students will complete all sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives:**\n",
    "* The objective of this project is to implement different regression models to analyze real-world datasets, understand the relationship between variables, and make predictions.  Additionally, students will gain experience understanding optimization techniques (gradient descent, stochastic gradient descent, and so-called ``normal equations\" to learn model parameter selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first problem we aim to analyze is a model similar to our class model of predicting how an audience might feel about a movie rating given the critic's score of the movie.  To get started, download the MovieData.csv file from the D2L project page.  This file contains an ordered pair $\\mathcal{D} = \\{(x^{(i)},t^{(i)})  \\}$ for $i = 1,2,\\dots,N$ samples.  Each pair represents a training example for the problem of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem A**\n",
    "\n",
    "1. Let's plot the data to get an idea of what we're dealing with (be sure to label all axis ``critic vs. audience\", and give the plot a title of your choosing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data (however you prefer), and plot the results using a scatter plot (don't forget your axis labels: Critic Score vs. Audience Score) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, write a function to compute the mean square error between two inputs (t_target,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition here, returns the mean square error between two inputs #\n",
    "def MSE(t_target, y_predicted):\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next write a function (called GradDescent)to learn the model parameters using gradient descent. \n",
    "    - The function will take as input, the target values, input values, and learning rate.\n",
    "    - The function will return the model parameters.\n",
    "\n",
    "**Note**  \n",
    "* You should assume the model takes the form (to generalize when we have more than a single input, e.g., the next problem will require fitting a more complex model to the data instead of a simple line)\n",
    "$$\n",
    "    y = w_0 + \\sum_{j=1}^M w_j x_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute linear regression using gradient descent #\n",
    "def GradDescent(t_target, x_input, l_learning_rate):\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Next, we learned in class that for linear models, we could use an analytic solution of the form:\n",
    "$$\n",
    "    \\textbf{w} = (X^T X)^{-1} X^T \\textbf{t}\n",
    "$$\n",
    "where $X$ and $\\textbf{t}$ are constructed as shown in class.  Write a function similar to the funciton in A.3 called LinRegression with input parameters $X$ and $\\textbf{t}$ that returns the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the linear model weights using the analytic solution (could also explore np.lstsq) #\n",
    "def LinRegression(X,t):\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using both function in problem A.3 and A.4, verify that the model parameters do indeed converge to the same values regardless of which method you use by plotting the original data, with two different lines on top: one for the gradient descent, and one for the analytic solution.\n",
    "    - Be sure to label all your plots and include a legend to distinguish between the scatter plot of original samples, and both line plots for your estimated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original data (scatter) with two different lines for each of your models computed above #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. To ensure the method for learning the model parameters is able to generalize well, use a 5-fold cross validation and 80/20 split of the data to build your model.  Using the MSE function above, compute the MSE for the validation set over all five folds and present the mean and deviation of the MSE.  You can use either method you choose for model validation, but I'd recommend using the analytic solution here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your linear model using 5-fold cross validation #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem B**\n",
    "1. Let's up the complexity a bit.  Download the second .csv file called HousingData.  This data contains housing prices (x1000) as a function of both size and year built.  Plot the data to get an idea of what we're dealing with (again, don't forget your axis labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapid City Housing Dataset - Data Dictionary\n",
    "\n",
    "**Dataset:** RapidCityHousing.csv  \n",
    "**Purpose:** Synthetic dataset for machine learning education (regression analysis)  \n",
    "**Observations:** 500 unique housing listings  \n",
    "**Features:** 10 predictor variables + 1 target variable  \n",
    "\n",
    "---\n",
    "\n",
    "## Feature Descriptions\n",
    "\n",
    "### Predictor Variables\n",
    "\n",
    "1. **Size_SqFt** (integer)\n",
    "   - House size in square feet\n",
    "   - Range: 800 - 4,000 sq ft\n",
    "   - Mean: ~1,806 sq ft\n",
    "   - Primary driver of price\n",
    "\n",
    "2. **Year_Built** (integer)\n",
    "   - Year the house was constructed\n",
    "   - Range: 1950 - 2024\n",
    "   - Mean: ~1986\n",
    "   - Non-linear relationship with price (depreciation curve)\n",
    "\n",
    "3. **Bedrooms** (integer)\n",
    "   - Number of bedrooms\n",
    "   - Range: 2 - 6\n",
    "   - Correlated with house size\n",
    "\n",
    "4. **Bathrooms** (float)\n",
    "   - Number of bathrooms (includes half-baths)\n",
    "   - Range: 1.0 - 4.5\n",
    "   - Increments of 0.5\n",
    "   - Correlated with size and bedrooms\n",
    "\n",
    "5. **Lot_Size_Acres** (float)\n",
    "   - Property lot size in acres\n",
    "   - Range: 0.1 - 2.0 acres\n",
    "   - Slight correlation with house size\n",
    "\n",
    "6. **Garage_Spaces** (integer)\n",
    "   - Number of car garage spaces\n",
    "   - Range: 0 - 3\n",
    "   - Most common: 2-car garage\n",
    "\n",
    "7. **Distance_Downtown_Miles** (float)\n",
    "   - Distance from downtown Rapid City in miles\n",
    "   - Range: 0.5 - 15 miles\n",
    "   - Slight negative correlation with price\n",
    "\n",
    "8. **Neighborhood_Quality** (integer)\n",
    "   - Subjective neighborhood quality score\n",
    "   - Range: 4 - 10 (scale of 1-10)\n",
    "   - Based on schools, amenities, crime rates, etc.\n",
    "\n",
    "9. **Days_On_Market** (integer)\n",
    "   - Number of days the listing has been active\n",
    "   - Range: 1 - 365 days\n",
    "   - Mean: ~45 days\n",
    "   - Slight negative correlation with price\n",
    "\n",
    "10. **Has_Basement** (binary: 0/1)\n",
    "    - Whether the house has a basement\n",
    "    - 0 = No basement\n",
    "    - 1 = Has basement\n",
    "    - ~70% of homes have basements\n",
    "\n",
    "### Target Variable\n",
    "\n",
    "11. **Price_Thousands** (float)\n",
    "    - Home sale price in thousands of dollars\n",
    "    - Range: $273k - $650k\n",
    "    - Mean: ~$433k\n",
    "    - To get actual price: multiply by 1,000\n",
    "\n",
    "---\n",
    "\n",
    "## Data Generation Methodology\n",
    "\n",
    "This is a **synthetic dataset** created for educational purposes with the following characteristics:\n",
    "\n",
    "### Realistic Relationships\n",
    "- **Primary driver:** Square footage has the strongest correlation with price (r = 0.936)\n",
    "- **Non-linear effects:** Age shows a depreciation curve, not linear decline\n",
    "- **Feature interactions:** Bedrooms/bathrooms correlated with size\n",
    "- **Market dynamics:** Days on market shows exponential distribution (most sell quickly)\n",
    "\n",
    "### Price Model\n",
    "The price was generated using a multi-factor model:\n",
    "```\n",
    "Price = f(size, size², age, age², bedrooms, bathrooms, lot_size, \n",
    "          garage, distance, neighborhood, basement, market_time) + noise\n",
    "```\n",
    "\n",
    "### Why Synthetic?\n",
    "- Avoids legal/ethical issues with scraping real estate sites\n",
    "- Allows controlled feature relationships for teaching\n",
    "- Ensures data quality and completeness\n",
    "- Can be freely shared and modified\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D scatter plot of the data to see what the data looks like #\n",
    "house_df = pd.read_csv(\"RapidCityHousing.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Assuming a linear model of the form $y = w_0 + w_1 x_1 + w_2 x_2$, use both methods described above to learn the model paramters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters learned here #\n",
    "# learn model parameters for the complex function above #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To investigate the model fit, let's plot the model surface along with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model surface here #\n",
    "\n",
    "\n",
    "# Predict values for meshgrid\n",
    "\n",
    "\n",
    "# Plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem C**\n",
    "* In Problem B, you assumed a linear model to fit the data, however, after further analysis of the data, you realized that a linear fit doesn't do a great job for this particular dataset.  Let's up the model complexity a bit to see if we can reduce the overall error in our model.\n",
    "    - As a \"guess\", let's assume the model is given by $y = w_0 + w_1 \\sqrt{(x_1 - 100)} + w_2 (x_2 - 1960)^2$\n",
    "    - Using this model, learn the model parameters to minimize the MSE (hint: you can use the analytic solution with proper choice of $X$)\n",
    "    - Plot the new model, along with the original data (as a surface plot) to illustrate the fit.\n",
    "    - Compare the MSE you get using the more complex model with the linear model you assumed in Problem B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn model parameters for the complex function above #\n",
    "# learn model parameters for the complex function above #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because this is a partner lab, you MUST list below who did what on the project to ensure equal contribution:\n",
    "\n",
    "### Partner A (Name):\n",
    "1. blah\n",
    "2. blah\n",
    "3. blah\n",
    "\n",
    "### Partner B (name):\n",
    "1. blah\n",
    "2. blah\n",
    "3. blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# CSC/DSE 548 Only! - Graduate students should work Problem D without the help of their partner!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem D**\n",
    "* In class we presented without proof that minimizing the MSE using gradient descent can be computed analytically for generalized linear models (GLMs).  Prove that this claim is indeed true.\n",
    "\n",
    "**Hint:** The following relationships may come in handy.\n",
    " $$\n",
    "   \\sum_{i=1}^N \\left( z^{(i)}  \\right)^2 = \\| \\textbf{z} \\|^2_2 = \\textbf{z}^T \\textbf{z}\n",
    "$$\n",
    "$$\n",
    "   \\frac{\\partial \\textbf{z}^T \\textbf{u}}{\\partial \\textbf{z}} = \\textbf{u}\n",
    "$$\n",
    "$$\n",
    "   \\frac{\\partial \\textbf{z}^T A \\textbf{z}}{\\partial \\textbf{z}} = (A + A^T) \\textbf{z}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>*Claim:*</ins> Given the linear model:\n",
    "     $$y(x) = w_0 + w_1 x$$ \n",
    "     with cost \n",
    "     $$\n",
    "        \\ell(\\textbf{w}) = \\frac{1}{2N} \\sum_{n=1}^N \\left[ t^{(n)} - y(x^{(n)}) \\right]^2,\n",
    "    $$\n",
    "    we can compute the model parameters analytically as:\n",
    "    $$\n",
    "        \\textbf{w} = \\left( X^T X \\right)^{-1} X^T \\textbf{t},\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>*Proof:*</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
